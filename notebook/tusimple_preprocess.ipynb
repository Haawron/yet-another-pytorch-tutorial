{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('./data/tusimple')\n",
    "ptrain = root / 'train_set'\n",
    "pimages = root / 'train_set_preprocessed/images'\n",
    "plabels = root / 'train_set_preprocessed/labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/tusimple/train_set/label_data_0313.json'),\n",
       " WindowsPath('data/tusimple/train_set/label_data_0531.json'),\n",
       " WindowsPath('data/tusimple/train_set/label_data_0601.json')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(pimages)\n",
    "shutil.rmtree(plabels)\n",
    "os.makedirs(pimages, exist_ok=True)\n",
    "os.makedirs(plabels, exist_ok=True)\n",
    "list(ptrain.glob('*.json')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1280x720 -> 320x180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 done\n",
      "1000 done\n",
      "1500 done\n",
      "2000 done\n",
      "2500 done\n",
      "3000 done\n",
      "3500 done\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "f_filenames = open(pimages.parent / 'filenames.txt', 'w')\n",
    "filenames = ''\n",
    "for plabel in ptrain.glob('*.json'):\n",
    "    with open(plabel, 'r') as f:\n",
    "        for line in f.readlines():  # for each image\n",
    "            label = json.loads(line.strip())\n",
    "            # 'lanes': 각 lane의 x 좌표들, -2이면 무시\n",
    "            # 'h_samples': y 값들\n",
    "            # 'raw_file': 이미지 경로, clip/...\n",
    "            \n",
    "            # x, y 나눠져 있는 점들을 [[x1, y1], [x2, y2], ...] 꼴로 바꿈\n",
    "            lanes = np.array(label['lanes'])\n",
    "            lanes = lanes.reshape(-1)\n",
    "            num_lanes = lanes.shape[0] // 48\n",
    "            h_samples = np.array(label['h_samples'])\n",
    "            h_samples = np.tile(h_samples, num_lanes)\n",
    "            valid_idx = lanes!=-2\n",
    "            x = np.c_[lanes[valid_idx], h_samples[valid_idx]]\n",
    "            x //= 4  # 가로, 세로 각각 1/4씩 줄어듦\n",
    "            \n",
    "            # 이미지 resize\n",
    "            image = Image.open(ptrain / label['raw_file']).convert('RGB')\n",
    "            image = image.resize((320, 180), Image.BICUBIC)\n",
    "            \n",
    "            # 저장\n",
    "            filename = Path('_'.join(label['raw_file'].split('/')[1:]))\n",
    "            np.save(plabels / filename.with_suffix('.npy'), x)\n",
    "            image.save(pimages / filename.with_suffix('.jpg'))\n",
    "            filenames += str(filename.stem) + '\\n'\n",
    "            count += 1\n",
    "            if count % 500 == 0:\n",
    "                print(f'\\r{count} done')\n",
    "f_filenames.write(filenames.strip())\n",
    "f_filenames.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pimages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-66c6b6275980>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'filenames.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpimages\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplabels\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pimages' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "with open(pimages.parent / 'filenames.txt', 'r') as f:\n",
    "    filename = Path(random.choice(f.readlines()).strip()) \n",
    "image = Image.open(pimages / filename.with_suffix('.jpg')).convert('RGB')\n",
    "label = np.load(plabels / filename.with_suffix('.npy'))\n",
    "\n",
    "r = 2\n",
    "draw = ImageDraw.Draw(image)\n",
    "for cx, cy in label:\n",
    "    leftUpPoint = (cx-r, cy-r)\n",
    "    rightDownPoint = (cx+r, cy+r)\n",
    "    twoPointList = [leftUpPoint, rightDownPoint]\n",
    "    draw.ellipse(twoPointList, fill=(255,0,0,255))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.crop((80, 45, 240, 135)).resize((320, 180))  # left, top, right, bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = [\n",
    "    # left, top, right, bottom\n",
    "    ( 80, 45, 240, 135),  # center\n",
    "    (  0,  0, 160,  90),  # leftupper\n",
    "    (  0, 90, 160, 180),  # leftbottom\n",
    "    (160,  0, 320,  90),  # rightupper\n",
    "    (160, 90, 320, 180),  # rightbottom\n",
    "]\n",
    "box = left, top, right, bottom = random.choice(boxes)\n",
    "labelx = label[:,0]\n",
    "labely = label[:,1]\n",
    "newlabel_idx = (left <= labelx) & (labelx < right) & (top  <= labely) & (labely < bottom)\n",
    "newlabel = label[newlabel_idx]\n",
    "newlabel -= np.array([[left, top]])\n",
    "newlabel *= 2\n",
    "\n",
    "newimage = image.crop(box).resize((320, 180))\n",
    "draw = ImageDraw.Draw(newimage)\n",
    "for cx, cy in newlabel:\n",
    "    leftUpPoint = (cx-r, cy-r)\n",
    "    rightDownPoint = (cx+r, cy+r)\n",
    "    twoPointList = [leftUpPoint, rightDownPoint]\n",
    "    draw.ellipse(twoPointList, fill=(0,0,255,255))\n",
    "newimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to build torch.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('./data/tusimple')\n",
    "ptrain = root / 'train_set'\n",
    "pimages = root / 'train_set_preprocessed/images'\n",
    "plabels = root / 'train_set_preprocessed/labels'\n",
    "boxes = [\n",
    "    # left, top, right, bottom\n",
    "    ( 80, 45, 240, 135),  # center\n",
    "    (  0,  0, 160,  90),  # leftupper\n",
    "    (  0, 90, 160, 180),  # leftbottom\n",
    "    (160,  0, 320,  90),  # rightupper\n",
    "    (160, 90, 320, 180),  # rightbottom\n",
    "]\n",
    "class TuSimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, p_crop=.4):\n",
    "        super().__init__()\n",
    "        self.p_crop = p_crop\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((.5, .5, .5), (.5, .5, .5)),\n",
    "        ])\n",
    "        with open(pimages.parent / 'filenames.txt', 'r') as f:\n",
    "            self.filenames = list(map(Path, f.read().split('\\n')))\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        filename = self.filenames[index]\n",
    "        image = Image.open(pimages / filename.with_suffix('.jpg')).convert('RGB')\n",
    "        label = np.load(plabels / filename.with_suffix('.npy'))  # [? x 2]\n",
    "        \n",
    "        if random.random() < self.p_crop:  # crop\n",
    "            box = left, top, right, bottom = random.choice(boxes)\n",
    "            image = image.crop(box).resize((320, 180))\n",
    "            labelx = label[:,0]\n",
    "            labely = label[:,1]\n",
    "            idx = (left <= labelx) & (labelx < right) & (top  <= labely) & (labely < bottom)  # [? x 2]\n",
    "            label = label[idx]  # [?? x 2]\n",
    "            label -= np.array([[left, top]])\n",
    "            label *= 2\n",
    "        \n",
    "        tmp = np.zeros((320, 180))\n",
    "        tmp[label[:,0], label[:,1]] = 1.\n",
    "        label = tmp.T[None,:,:]  # [1 x 180 x 320]  # 가로세로 왜 바꾼지는 모르겠는데 암튼 바껴있음\n",
    "        return self.transform(image), label  # [3 x 180 x 320], [1 x 180 x 320]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = TuSimpleDataset()\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "for batch_idx, (image, label) in enumerate(dataloader):\n",
    "    break\n",
    "image.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(name, blocks, x):\n",
    "    print('='*60)\n",
    "    print(f'Module [{name}]')\n",
    "    print(f'\\tInput{str(list(x.shape)):>47}')\n",
    "    with torch.no_grad():\n",
    "        count_layer = 1\n",
    "        for i, block in enumerate(blocks):\n",
    "            x = block(x)\n",
    "            print(f'\\tBlock #{i+1}')\n",
    "            for layer in block:\n",
    "                class_name = str(layer.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "                print(f'\\t  Layer {f\"#{count_layer}\":>3} {class_name}')\n",
    "                count_layer += 1\n",
    "            print(f'{str(list(x.shape)):>60}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = None\n",
    "        self.blocks = None\n",
    "    def build_graph(self, blocks):\n",
    "        return nn.ModuleList(map(lambda block: nn.Sequential(*block), blocks))\n",
    "    def __validate(self):\n",
    "        assert self.name,   '`self.name` is not defined'\n",
    "        assert self.blocks, '`self.blocks` is not defined. Build one using self.build_graph(blocks)'\n",
    "    def summarize(self, x):\n",
    "        self.__validate()\n",
    "        summarize(self.name, self.blocks, x) \n",
    "    def forward(self, x):\n",
    "        self.__validate()\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extracter(BaseModel):\n",
    "    def __init__(self, name='Feature Extracter'):\n",
    "        super().__init__() \n",
    "        self.name = name\n",
    "        blocks = [\n",
    "            (\n",
    "                nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1, bias=True),\n",
    "                nn.InstanceNorm2d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ), (\n",
    "                nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        ]\n",
    "        self.blocks = self.build_graph(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 3, 180, 320)\n",
    "extracter = Extracter()\n",
    "f = extracter(x) \n",
    "extracter.summarize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ModelMuSigma(BaseModel):\n",
    "    def __init__(self, dim_k, name='MoL MuSigma'):\n",
    "        super().__init__() \n",
    "        self.name = name\n",
    "        blocks = [\n",
    "            (\n",
    "                nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1, bias=True),\n",
    "                nn.InstanceNorm2d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ), (    \n",
    "                nn.ConvTranspose2d(32, dim_k, kernel_size=3, stride=2, padding=1, output_padding=1, bias=True),\n",
    "            ),\n",
    "        ]\n",
    "        self.blocks = self.build_graph(blocks) \n",
    "\n",
    "model_mu = ModelMuSigma()\n",
    "model_mu.summarize(f)\n",
    "mu = model_mu(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPi(BaseModel):\n",
    "    def __init__(self, dim_k, name='MoL Pi'):\n",
    "        super().__init__() \n",
    "        self.name = name\n",
    "        blocks = [\n",
    "            (\n",
    "                nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=True),\n",
    "                nn.InstanceNorm2d(128),\n",
    "                nn.LeakyReLU(.2, inplace=True),\n",
    "            ), (    \n",
    "                nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1, bias=True),\n",
    "                nn.InstanceNorm2d(128),\n",
    "                nn.LeakyReLU(.2, inplace=True),\n",
    "            ), (\n",
    "                nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=True),\n",
    "                nn.InstanceNorm2d(256),\n",
    "                nn.LeakyReLU(.2, inplace=True),\n",
    "            ), (\n",
    "                nn.Conv2d(256, dim_k//2, kernel_size=5, stride=5, padding=0, bias=True),\n",
    "                nn.LeakyReLU(.2, inplace=True),\n",
    "            ), (\n",
    "                nn.Flatten(),\n",
    "                nn.Softmax(1),\n",
    "            )\n",
    "        ]\n",
    "        self.blocks = self.build_graph(blocks) \n",
    "\n",
    "model_pi = ModelPi(dim_k=10)\n",
    "pi = model_pi(f)\n",
    "model_pi.summarize(f)  \n",
    "pi, pi.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureLogitsNetwork(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim_k      = 10,\n",
    "                 # todo: multi class를 위한 dim_y 추가, SHARE_SIG도 추가\n",
    "                 sig_min    = 1e-4, \n",
    "                 mu_min     = -3,           # minimum mu (init)\n",
    "                 mu_max     = +3,           # maximum mu (init)\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.dim_k   = dim_k\n",
    "        self.sig_min = sig_min\n",
    "        self.mu_min  = mu_min\n",
    "        self.mu_max  = mu_max\n",
    "        self.build_graph()\n",
    "        self.init_param() \n",
    "    def build_graph(self):\n",
    "        self.extracter   = Extracter()\n",
    "        self.model_pi    = ModelPi(dim_k=self.dim_k)\n",
    "        self.model_mu    = ModelMuSigma(dim_k=self.dim_k, name='MoL Mu')\n",
    "        self.model_sigma = ModelMuSigma(dim_k=self.dim_k, name='MoL Sigma')\n",
    "    def init_param(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)): # init conv\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            if isinstance(m, nn.Linear): # init dense\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        # Heuristic: fc_mu.bias ~ Uniform(mu_min,mu_max)\n",
    "        list(self.model_mu.modules())[-1].bias.data.uniform_(self.mu_min,self.mu_max)\n",
    "    def summarize(self, x):\n",
    "        self.extracter.summarize(x)\n",
    "        with torch.no_grad():\n",
    "            f = self.extracter(x)\n",
    "        self.model_pi.summarize(f)\n",
    "        self.model_mu.summarize(f)\n",
    "        self.model_sigma.summarize(f)\n",
    "    def forward(self, x):\n",
    "        f     = self.extracter(x)\n",
    "        \n",
    "        pi    = self.model_pi(f)\n",
    "        mu    = self.model_mu(f)\n",
    "        sigma = self.sig_min + torch.exp(self.model_sigma(f))\n",
    "        return {'pi': pi, 'mu': mu, 'sigma': sigma}\n",
    "\n",
    "x = torch.randn(4, 3, 180, 320)\n",
    "mln = MixtureLogitsNetwork()\n",
    "mln.summarize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 3.7 GPU",
   "language": "python",
   "name": "torch37gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
